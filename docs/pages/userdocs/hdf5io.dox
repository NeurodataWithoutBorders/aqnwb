/**
 * \page hdf5io HDF5 I/O ðŸ“‚
 *
 * \tableofcontents
 *
 * \section hdf5io_data_layout Optimizing Data Layout 
 *
 * HDF5 supports advanced I/O features for optimizing the layout of large data arrays
 * via \ref hdf5io_chunking "Chunking" and \ref hdf5io_filters "I/O Filters". Below
 * we discuss these features in more detail. The main classes involved in configuring
 * chunking and I/O filters in HDF5 via AQNWB are: 
 *
 * - \ref AQNWB::IO::ArrayDataSetConfig "ArrayDataSetConfig" for configuring datasets
 *   for write, including chunking settings. 
 *    - \ref AQNWB::IO::HDF5::HDF5ArrayDataSetConfig "HDF5ArrayDataSetConfig" then extends the basic
 *      \ref AQNWB::IO::ArrayDataSetConfig "ArrayDataSetConfig" to add HDF5-specific configurations, 
 *      such as, support for configuring I/O filters (e.g., for compression)
 *    - \ref AQNWB::IO::HDF5::HDF5FilterConfig "HDF5FilterConfig" is used with 
 *           \ref AQNWB::IO::HDF5::HDF5ArrayDataSetConfig "HDF5ArrayDataSetConfig" to configure
 *           a single I/O filter.
 * - \ref AQNWB::IO::HDF5::HDF5IO::createArrayDataSet "HDF5IO::createArrayDataSet" is the main 
 *   method used for creating n-dimensional array datasets
 *
 * \subsection hdf5io_chunking Chunking
 *
 * For datasets intended for recording, `AqNWB` uses chunking to ensure the dataset
 * can be extended as new data arrives during the recording process.
 * Using chunking in HDF5, a dataset is divided into fixed-size blocks (called chunks),
 * which are stored separately in the file. This technique is particularly
 * beneficial for large datasets and offers several advantages:
 *
 * - **Extend datasets**: Chunked datasets can be easily extended in any dimension.
 *    This flexibility is crucial for recording datasets where the size of the dataset
 *    is not known in advance.
 * - **Performance Optimization**: By carefully choosing the chunk size, you can optimize
 *    performance based on your particular read/write access patterns. When only a portion
 *    of a chunked dataset is accessed, only the relevant chunks are read or written,
 *    reducing the amount of I/O operations.
 * - **Compression**: Data within each chunk can be compressed independently, which can help
 *   to significant reduce data size, especially for datasets with redundancy (see \ref hdf5io_filters).
 *
 *
 * \warning
 * Choosing a chunking configuration that does not align well with the desired read/write pattern
 * may lead to reduced performance due to repeated read, decompression, and update to the same
 * chunk or read of extra data as chunks are always read fully.
 *
 *
 *
 * \dot
 * digraph Chunking {
 *     node [shape=plaintext];
 *
 *     // Define the HDF5 file node with a distinct shape
 *     subgraph cluster_0 {
 *         label="HDF5 File";
 *         style=filled;
 *         shape=folder;
 *         color=white;
 *         penwidth=1;
 *         pencolor=black;
 *
 *         // Define the dataset node
 *         dataset [label=<
 *             <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0">
 *                 <TR>
 *                     <TD COLSPAN="2" BGCOLOR="lightblue">HDF5 Dataset</TD>
 *                 </TR>
 *                 <TR>
 *                     <TD PORT="chunk1" BGCOLOR="lightgreen">
 *                         <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0">
 *                             <TR><TD></TD><TD></TD></TR>
 *                             <TR><TD></TD><TD></TD></TR>
 *                         </TABLE>
 *                     </TD>
 *                     <TD PORT="chunk3" BGCOLOR="lightgreen">
 *                         <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0">
 *                             <TR><TD></TD><TD></TD></TR>
 *                             <TR><TD></TD><TD></TD></TR>
 *                         </TABLE>
 *                     </TD>
 *                 </TR>
 *                 <TR>
 *                     <TD PORT="chunk2" BGCOLOR="lightgreen">
 *                         <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0">
 *                             <TR><TD></TD><TD></TD></TR>
 *                             <TR><TD></TD><TD></TD></TR>
 *                         </TABLE>
 *                     </TD>
 *                     <TD PORT="chunk4" BGCOLOR="lightgreen">
 *                         <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0">
 *                             <TR><TD></TD><TD></TD></TR>
 *                             <TR><TD></TD><TD></TD></TR>
 *                         </TABLE>
 *                     </TD>
 *                 </TR>
 *             </TABLE>
 *         >];
 *
 *         // Define the chunks
 *         chunk1 [label="Chunk 1", shape=box, fillcolor=lightgreen, style=filled];
 *         chunk2 [label="Chunk 2", shape=box, fillcolor=lightgreen, style=filled];
 *         chunk4 [label="Chunk 4", shape=box, fillcolor=lightgreen, style=filled];
 *         chunk3 [label="Chunk 3", shape=box, fillcolor=lightgreen, style=filled];
 *
 *         // Define the edges
 *         dataset:chunk1 -> chunk1 [label=""];
 *         dataset:chunk2 -> chunk2 [label=""];
 *         dataset:chunk3 -> chunk3 [label=""];
 *         dataset:chunk4 -> chunk4 [label=""];
 *     }
 * }
 * \enddot
 *
 *
 *
 * \subsection hdf5io_filters I/O Filters and Compression 
 *
 * HDF5 filters are used to transform data as it is written to and read from the file.
 * Filters are applied on a per-chunk basis (i.e., chunking is required to use filters), and 
 * are typically used for compression or error detection.
 * 
 * Compression filters reduce the amount of storage space required for datasets by eliminating
 * redundancy in the data. One commonly used compression filter is ``GZIP (DEFLATE)``  which 
 * provides a good balance between compression ratio and speed. Multiple filters may be applied 
 * simultaneously. E.g., the ``Shuffle`` filter can be used to rearrange the bytes in the data to
 * improve the effectiveness of compression filters. By shuffling the data, redundancy within 
 * the byte stream is increased, which can help improve compression ratios. For
 * more information on the available filters in HDF5, please refer to the
 * [HDF5 Data Pipeline Filters Documentation](https://support.hdfgroup.org/documentation/hdf5/latest/_h5_d__u_g.html#subsubsec_dataset_transfer_filter)
 * by the HDF5 project. 
 * 
 * \subsection hdf5io_filters_usage Using Chunking and I/O Filters in AqNWB
 * 
 * When creating datasets, you can specify the filters to be applied using the 
 * \ref AQNWB::IO::HDF5::HDF5ArrayDataSetConfig "HDF5ArrayDataSetConfig" class.
 * The following example demonstrates how to configure and apply the GZIP and 
 * Shuffle filters to a dataset. The \ref AQNWB::IO::HDF5::HDF5ArrayDataSetConfig "HDF5ArrayDataSetConfig" 
 * class allows you to specify the data type, shape, chunking, and filters
 * for the dataset. The \ref AQNWB::IO::HDF5::HDF5IO::createArrayDataSet "HDF5IO::createArrayDataSet" 
 * method then creates the dataset with the specified configuration.
 *
 * \snippet tests/examples/test_HDF5IO_examples.cpp example_HDF5_with_filters
 * 
 * \note 
 * \ref AQNWB::IO::HDF5::HDF5FilterConfig "HDF5FilterConfig" provides convenient
 * factory methods to setup common filters, e.g., \ref AQNWB::IO::HDF5::HDF5FilterConfig::createGzipFilter "createGzipFilter".
 * Alternatively, we can also use any of the HDF5 filters directly via 
 * \ref AQNWB::IO::HDF5::HDF5ArrayDataSetConfig::addFilter "HDF5ArrayDataSetConfig::addFilter",  
 * e.g., in the case of GZIP via ``config.addFilter(H5Z_FILTER_DEFLATE, {4});`` 
 * 
 *
 * \section hdf5io_swmr Single-Writer Multiple-Reader (SWMR) Mode
 *
 * The \ref AQNWB::IO::HDF5::HDF5IO "HDF5IO" I/O backend uses by default SWMR mode while recording data.
 * Using SWMR, one process can write to the HDF5 file and multiple other processes can read
 * from the file concurrently while ensuring that the readers see a consistent view of the data.
 *
 * \dot
 * digraph SWMR {
 *     size="4,3"; // Set the size of the diagram to 4 inches wide by 3 inches tall
 *     node [shape=box, style=filled];
 *
 *     // Define the writer node with light blue fill color
 *     writer [label="AqNWB HDF5IO\n(SWMR Write)", fillcolor=lightblue, URL="\ref AQNWB::IO::HDF5::HDF5IO"];
 *     // Define the HDF5 file node with a distinct shape
 *     hdf5_file [label="\n.nwb\n(HDF5 File)\n ", shape=folder, fillcolor=lightgray, URL="\ref AQNWB::NWB::NWBFile"];
 *     // Define reader nodes with light green fill color
 *     reader1 [label="Reader 1\n(SWMR Read)", fillcolor=lightgreen, URL="\ref hdf5io_swmr_read"];
 *     reader2 [label="Reader 2\n(SWMR Read)", fillcolor=lightgreen, URL="\ref hdf5io_swmr_read"];
 *     reader3 [label="Reader 3\n(SWMR Read)", fillcolor=lightgreen, URL="\ref hdf5io_swmr_read"];
 *
 *     // Set the rank for the nodes
 *     { rank=source; writer; }
 *     { rank=same; hdf5_file; }
 *     { rank=sink; reader1; reader2; reader3; }
 *
 *     // Define the edges
 *     writer -> hdf5_file [label="Write"];
 *     reader1 -> hdf5_file [label="Read"];
 *     reader2 -> hdf5_file [label="Read"];
 *     reader3 -> hdf5_file [label="Read"];
 * }
 * \enddot
 *
 * \warning
 * There are known issues using SWMR mode on Windows due to file locking by the reader processes. One workaround
 * is to set the environment variable `HDF5_USE_FILE_LOCKING=FALSE` to prevent file access errors when using 
 * a writer process with other reader processes.  
 *
 * \subsection hdf5io_swmr_features Why does AqNWB use SMWR mode?
 *
 * Using SWMR has several key advantages for data acquisition applications:
 *
 * - \b Concurrent \b Access: Enables one writer process to update the file while
 *   multiple reader processes read from it without blocking each other.
 * - \b Data \b Consistency \b and \b Integrity: Ensures that readers see a consistent view of
 *   the data, even as it is being written. Readers will only see data that has been completely
 *   written and flushed to disk. Hence, SWMR mode, maintains the integrity and consistency of
 *   the data, ensuring that the HDF5 file remains readable even if errors should occur during
 *   the data acquisition process.
 * - \b Real-Time \b Data \b Access: Useful for applications that need to monitor
 *   and analyze data in real-time as it is being generated.
 * - \b Simplified \b Workflow \b for \b Real \b Time \b Analyses: Simplifies the
 *   architecture of applications that require real-time data consumption during acquisition,
 *   avoiding the need for intermediate storage solutions and complex inter-process communication
 *   or file locking mechanisms.
 *
 * \note
 * While SWMR mode ensures data integrity, some data loss may still occur if the application crashes.
 * Only data that has been completely written and flushed to disk will be readable. To manually
 * flush data to disk use \ref AQNWB::IO::HDF5::HDF5IO::flush  "HDF5IO::flush".
 *
 * \subsection  hdf5io_swmr_workflow Writing an NWB file with SWMR mode
 *
 * SWMR mode is enabled when calling \ref AQNWB::IO::HDF5::HDF5IO::startRecording "HDF5IO::startRecording".
 * Once SWMR mode is enabled, no new data objects (Datasets, Groups, Attributes etc.)
 * can be created, but we can only add and set values to existing data objects. Since other
 * processes may read from the HDF5 file, it is not possible to intermittently disable
 * SWMR mode to add new objects, i.e., once SWMR mode is enabled, the only way to add
 * new objects to the file is to close the file and reopen in read/write mode.  As such,
 * the typical workflow when using SWMR mode during data acquisition is to:
 *
 * 1. Open the HDF5 file
 * 2. Create all elements of the NWB file
 * 3. Start the recording process
 * 4. Stop recording and close the file
 *
 * This workflow is applicable to a wide range of data acquisition use-cases. However,
 * for use cases that require creation of new Groups and Datasets during acquisition,
 * you can disable the use of SWMR mode by setting `disableSWMRMode=true` when
 * constructing the \ref AQNWB::IO::HDF5::HDF5IO object.
 *
 * \warning
 * While disabling SWMR mode allows Groups and Datasets to be created during and after
 * recording, this comes at the  cost of losing the concurrent access and data integrity
 * features that SWMR mode provides.
 *
 * \subsubsection hdf5io_swmr_examples Code Examples
 *
 * This code snippet shows all the includes that are being used by the code examples
 * shown in this section:
 *
 * \snippet tests/examples/test_HDF5IO_examples.cpp example_HDF5_includes
 *
 * \paragraph  hdf5io_swmr_examples_with_swmr Workflow with SWMR
 *
 * \snippet tests/examples/test_HDF5IO_examples.cpp example_HDF5_with_SWMR_mode
 *
 * \paragraph  hdf5io_noswmr_examples_without_swmr Workflow with SWMR disabled
 *
 * \snippet tests/examples/test_HDF5IO_examples.cpp example_HDF5_without_SWMR_mode
 *
 *
 * \subsection  hdf5io_swmr_read Reading with SWMR mode
 *
 * While the file is being written to in SWMR mode, readers must open the file with
 * the ``H5F_ACC_RDONLY`` flag and then enable SWMR read mode using the ``H5Fstart_swmr_read``
 * function, e.g.:
 *
 * \code{.c}
 *  hid_t file_id = H5Fopen("example.h5", H5F_ACC_RDONLY, H5P_DEFAULT);
 *  H5Fstart_swmr_read(file_id);
 * \endcode
 */
